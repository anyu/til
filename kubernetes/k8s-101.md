# Kubernetes 101

## Kubernetes Architecture

Deploying k8s gets you a cluster.

A cluster consists of:
- **control plane** node â€“ essentially the cluster's brain and coordinates cluster activities (scheduling/scaling apps, maintaining desired state).
- at least 1 **worker** node - deploys and runs containerized apps.

A node is a single VM or physical compute machine.

### Control Plane Components

Technically control plane component instances can be run on any node.
Generally, the components are configured on the same node, though sometimes etcd is set up [external to the cluster](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/#external-etcd-topology).

#### I. kube-apiserver (API server)
- serves the API, does validation/authentication/authorization/manages read+writes to etcd
- main entrypoint for interacting with the cluster
- accessible via kubectl, REST calls, etc

#### II. etcd (distributed kv store)
- the backing state store/source of truth for all cluster data (configuration, cluster state)
- uses the Raft algorithm to keep data in sync across etcd nodes

#### III. kube-controller-manager (cluster controller manager)
- consists of different controllers (basically control-loop) that watch the state of the cluster (in etcd) and reacts when needed
- controllers move the current state toward the desired state, aka "reconciliation".
- a controller tracks at least 1 k8s resource type.
- "built-in" controllers manage state via the API server; non built-in controllers may manage state directly
- some examples of controllers ([full list](https://github.com/kubernetes/kubernetes/tree/master/pkg/controller):
  - **deployment controller**: notices new deployment, creates a replicaset, updates etcd
  - **replicaset controller**: looks at the etcd info, extracts it, creates pods
  - **node controller**: responds when nodes go down
  - **job controller**: watches for one-off Jobs tasks, creates pods to run those tasks

#### IV. kube-scheduler (scheduler)
- watches etcd via API server for newly created pods and selects nodes for them to run on based on available resources

---

### Node Components

The following components run on every node.

Note: Control plane nodes are generally configured as regular worker nodes, so also have the following components. However, they are automatically tainted by `kubeadm` to prevent workloads being run on them.

#### I. kubelet
- an agent that communicates w/ the control plane via k8s API
- ensures that containers within pods are running/healthy

#### II. container runtime
- runs the containers inside the nodes
- eg. Docker, containerd
- kubelet communicates with API server and compares desired # of pods running with actual, then interacts with the container runtime to reconcile the state

#### III. kube-proxy
- a network proxy that allows communication to pods from inside or outside of the cluster
- runs as a daemonset on all nodes; programs iptables rules so that pods can talk to each other

---

### Pods
- atomic unit. Smallest deployable unit in k8s.
- a set of running containers with shared storage and networking. Similar to a set of Docker containers w/ shared namespaces.
- 1 pod is meant to run 1 app instance; other containers on the same pod are usually for sidecar processes

### Workload Resources

Pods are created/managed via workload resources, which creates pods from templates.

- **Deployment**: resource for managing stateless application workload
  - recommended over using Replicasets directly
- **StatefulSets**: resource for running 1+ related pods that are stateful (eg. can match pods up with a persistent volume)
- **DaemonSet**: pods that provide node-local facilities. Everytime a node is added, the control plane schedules
- **Job**: tasks that run then stop (can be one-off tasks or crons)

When a pod template for a workload resource is changed, new pods are created vs. existing pods being updated

CRDs (custom resource definitions) can be used for third-party resources.
